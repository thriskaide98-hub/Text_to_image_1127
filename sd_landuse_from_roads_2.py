"""
sd_landuse_from_roads.py (clean roads + masked outside)

- input/roads/{id}_condition.png  : ë„ë¡œ + ì£¼ë³€ ë§µ
- input/masks/{id}_mask.png       : ëŒ€ìƒì§€(í°ìƒ‰) / ë°°ê²½(ê²€ì •) ë§ˆìŠ¤í¬
- Stable Diffusion + ControlNet ìœ¼ë¡œ land-use ì´ë¯¸ì§€ ìƒì„±
- ê²°ê³¼: result/sd_landuse/{id}_landuse.png
"""

from pathlib import Path

import torch
import numpy as np
from PIL import Image, ImageDraw

from diffusers import StableDiffusionControlNetPipeline, ControlNetModel


# -------------------------
# 1. ê¸°ë³¸ ì„¤ì •
# -------------------------

ROOT_DIR = Path(__file__).resolve().parent
ROADS_DIR = ROOT_DIR / "input" / "roads"
MASKS_DIR = ROOT_DIR / "input" / "masks"
OUT_DIR   = ROOT_DIR / "result/0.main&sd/sd" / "sd_landuse_2"
OUT_DIR.mkdir(parents=True, exist_ok=True)

SD_MODEL_ID = "runwayml/stable-diffusion-v1-5"
CONTROLNET_MODEL_ID = "lllyasviel/sd-controlnet-scribble"

PROMPT_BASE = (
    "flat top-down urban land-use planning map, schematic, vector map style, "
    "solid flat colors only, no textures, no shadows, no gradients, "
    "roads strictly follow the given line drawing, "
    "yellow residential blocks, red commercial corridors and centers, "
    "blue public and institutional facilities, "
    "green parks and open spaces, "
    "clean map, high contrast, minimalistic design, no labels, no text"
)

NEGATIVE_PROMPT = (
    "photo, realistic, satellite imagery, terrain, aerial photo, "
    "3d, perspective, buildings details, windows, cars, people, "
    "trees with texture, fog, shadow, reflection, noise, blur, "
    "sketch text, labels, numbers, watermark"
)

NUM_STEPS       = 35
GUIDANCE        = 10.0
CONTROL_SCALE   = 1.1
TARGET_SIZE     = (768, 768)  # cond/mask resize í¬ê¸°


# -------------------------
# 2. íŒŒì´í”„ë¼ì¸ ë¡œë“œ
# -------------------------

def load_pipeline(device: str = "cuda"):
    print("ğŸ”¹ Loading ControlNet model...")
    controlnet = ControlNetModel.from_pretrained(
        CONTROLNET_MODEL_ID,
        torch_dtype=torch.float16,
    )

    print("ğŸ”¹ Loading Stable Diffusion + ControlNet pipeline...")
    pipe = StableDiffusionControlNetPipeline.from_pretrained(
        SD_MODEL_ID,
        controlnet=controlnet,
        torch_dtype=torch.float16,
        safety_checker=None,
    ).to(device)

    pipe.enable_attention_slicing()
    return pipe


# -------------------------
# 3. ìœ í‹¸
# -------------------------

def load_pair_images(id_str: str):
    cond_path = ROADS_DIR / f"{id_str}_condition.png"
    mask_path = MASKS_DIR / f"{id_str}_mask.png"
    if not cond_path.exists():
        raise FileNotFoundError(cond_path)
    if not mask_path.exists():
        raise FileNotFoundError(mask_path)

    cond = Image.open(cond_path).convert("RGB").resize(TARGET_SIZE)
    mask = Image.open(mask_path).convert("L").resize(TARGET_SIZE)

    return cond, mask


def pre_mask_condition(cond: Image.Image, mask: Image.Image) -> Image.Image:
    """
    ControlNetì— ë„£ê¸° ì „ì—: ëŒ€ìƒì§€ ë°–(ê²€ì • ì˜ì—­)ì„ ì™„ì „ í°ìƒ‰ìœ¼ë¡œ ë§Œë“¤ì–´ ì¤Œ.
    """
    c = np.array(cond)
    m = np.array(mask)
    outside = m < 128
    c[outside] = 255
    return Image.fromarray(c)


def overlay_roads_on_top(base: Image.Image, cond: Image.Image) -> Image.Image:
    """
    ìµœì¢… ê²°ê³¼ ìœ„ì— roadsë¥¼ íšŒìƒ‰/ê²€ì • ì„ ìœ¼ë¡œ ë‹¤ì‹œ ë§ê·¸ë¦¬ê¸°.
    - cond: ì›ë˜ ë„ë¡œ ì´ë¯¸ì§€ (RGB)
    """
    base_np = np.array(base)
    cond_gray = np.array(cond.convert("L"))

    # ë„ë¡œ ì¶”ì¶œ (ë°ì€ ë„ë¡œë¼ë©´ threshold ë°˜ëŒ€ë¡œ ë°”ê¿”ì•¼ í•  ìˆ˜ë„ ìˆìŒ)
    # ì—¬ê¸°ì„œëŠ” "ë„ë¡œê°€ ë¹„êµì  ë°ì€ íšŒìƒ‰"ì´ë¼ê³  ê°€ì •í•˜ê³  Canny ëŒ€ì‹  ê°„ë‹¨ threshold ì‚¬ìš©
    road_mask = cond_gray < 230  # ê°’ì€ ë°ì´í„° ë³´ê³  ì¡°ì •

    # íšŒìƒ‰(ë˜ëŠ” ê²€ì •) ê°’
    road_color = np.array([180, 180, 180], dtype=np.uint8)

    base_np[road_mask] = road_color

    return Image.fromarray(base_np)


def apply_mask_final(img: Image.Image, mask: Image.Image) -> Image.Image:
    """
    ìµœì¢… ê²°ê³¼ì—ì„œ ëŒ€ìƒì§€ ë°–ì„ í°ìƒ‰ìœ¼ë¡œ ì •ë¦¬.
    """
    img_np = np.array(img)
    mask_np = np.array(mask)
    outside = mask_np < 128
    img_np[outside] = 255
    return Image.fromarray(img_np)


# -------------------------
# 4. ìƒì„± í•¨ìˆ˜
# -------------------------

def generate_landuse_for_id(pipe, id_str: str, device: str = "cuda"):
    cond_raw, mask = load_pair_images(id_str)

    # 1) ControlNet inputìš© cond: ëŒ€ìƒì§€ ë°–ì€ ë¯¸ë¦¬ í°ìƒ‰ ì²˜ë¦¬
    cond_for_cn = pre_mask_condition(cond_raw, mask)

    print(f"ğŸ”¹ Generating land-use image for id={id_str} ...")
    generator = torch.Generator(device=device).manual_seed(1234)

    out = pipe(
        prompt=PROMPT_BASE,
        image=cond_for_cn,
        num_inference_steps=NUM_STEPS,
        guidance_scale=GUIDANCE,
        controlnet_conditioning_scale=CONTROL_SCALE,
        negative_prompt=NEGATIVE_PROMPT,
        generator=generator,
    )

    gen = out.images[0]

    # 2) ê²°ê³¼ ìœ„ì— roadsë¥¼ ë‹¤ì‹œ íšŒìƒ‰ìœ¼ë¡œ overwrite
    gen_with_roads = overlay_roads_on_top(gen, cond_for_cn)

    # 3) ìµœì¢…ì ìœ¼ë¡œ ëŒ€ìƒì§€ ë°–ì€ ì „ë¶€ í°ìƒ‰
    final_img = apply_mask_final(gen_with_roads, mask)

    out_path = OUT_DIR / f"{id_str}_landuse.png"
    final_img.save(out_path)
    print(f"âœ… Saved: {out_path}")


# -------------------------
# 5. ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# -------------------------

def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print("ğŸ‘‰ Using device:", device)

    pipe = load_pipeline(device=device)

    ids = sorted(
        p.stem.replace("_condition", "") for p in ROADS_DIR.glob("*_condition.png")
    )
    print("ğŸ¯ Target IDs:", ids)

    for id_str in ids:
        generate_landuse_for_id(pipe, id_str, device=device)


if __name__ == "__main__":
    main()
