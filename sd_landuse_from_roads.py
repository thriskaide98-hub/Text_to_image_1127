"""
sd_landuse_from_roads.py

- ì‹¤ì œ ë„ë¡œë§ ì´ë¯¸ì§€ë¥¼ ControlNet ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©
- Stable Diffusionìœ¼ë¡œ í† ì§€ì´ìš©ê³„íš(ì£¼ê±°/ìƒì—…/ê³µê³µ/ë…¹ì§€) íƒ‘ë·° ì´ë¯¸ì§€ ìƒì„±
- ê²°ê³¼ëŠ” result/sd_landuse/{id}_landuse.png ë¡œ ì €ì¥
"""

import os
from pathlib import Path

import torch
import numpy as np
from PIL import Image
import cv2

from diffusers import (
    StableDiffusionControlNetPipeline,
    ControlNetModel,
)


# =========================
# 1. ê¸°ë³¸ ì„¤ì •
# =========================

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ
ROOT_DIR = Path(__file__).resolve().parent
ROADS_DIR = ROOT_DIR / "input" / "roads"
MASKS_DIR = ROOT_DIR / "input" / "masks"
OUT_DIR   = ROOT_DIR / "result/0.main&sd/sd" / "sd_landuse"

OUT_DIR.mkdir(parents=True, exist_ok=True)

# ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ì›í•˜ë©´ ë„¤ê°€ ì“°ëŠ” ëª¨ë¸ë¡œ ë³€ê²½)
SD_MODEL_ID = "runwayml/stable-diffusion-v1-5"
CONTROLNET_MODEL_ID = "lllyasviel/sd-controlnet-scribble"  # ë¼ì¸/ìŠ¤ì¼€ì¹˜ìš©

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê³„íšë„ ìŠ¤íƒ€ì¼ ê°•ì¡°)
PROMPT_BASE = (
    "flat top-down urban land-use planning map, schematic, vector map style, "
    "solid flat colors only, no textures, no shadows, no gradients, "
    "roads strictly follow the given line drawing, "
    "yellow residential blocks, red commercial corridors and centers, "
    "blue public and institutional facilities, "
    "green parks and open spaces, "
    "clean map, high contrast, minimalistic design, no labels, no text"
)

NEGATIVE_PROMPT = (
    "photo, realistic, satellite imagery, terrain, aerial photo, "
    "3d, perspective, buildings details, windows, cars, people, trees with texture, "
    "fog, shadow, reflection, noise, blur, sketch, hand-drawn text, labels, numbers, watermark"
)

# ìƒì„± íŒŒë¼ë¯¸í„°
NUM_STEPS = 40              # ë””í…Œì¼ í™•ë³´
GUIDANCE = 11.0             # í”„ë¡¬í”„íŠ¸ ì˜í–¥ ê°•í•˜ê²Œ
CONTROL_SCALE = 1.2         # ë„ë¡œë§ì„ ë” ê°•í•˜ê²Œ ìœ ì§€


# =========================
# 2. íŒŒì´í”„ë¼ì¸ ë¡œë“œ
# =========================

def load_pipeline(device: str = "cuda"):
    print("ğŸ”¹ Loading ControlNet model...")
    controlnet = ControlNetModel.from_pretrained(
        CONTROLNET_MODEL_ID,
        torch_dtype=torch.float16
    )

    print("ğŸ”¹ Loading Stable Diffusion + ControlNet pipeline...")
    pipe = StableDiffusionControlNetPipeline.from_pretrained(
        SD_MODEL_ID,
        controlnet=controlnet,
        torch_dtype=torch.float16,
        safety_checker=None,
    ).to(device)

    # xformersê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì€ ì„œë²„ì—ì„œëŠ” ì´ ì˜µì…˜ì„ ì¼œë©´ ì—ëŸ¬ê°€ ë‚˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
    # pipe.enable_xformers_memory_efficient_attention()

    # ì´ê±´ ë©”ëª¨ë¦¬ ì¡°ê¸ˆ ëœ ì“°ê²Œ í•´ì£¼ëŠ” ì˜µì…˜ì´ë¼ ìœ ì§€í•´ë„ ê´œì°®ìŒ
    pipe.enable_attention_slicing()

    return pipe


# =========================
# 3. ìœ í‹¸ í•¨ìˆ˜
# =========================

def load_pair_images(id_str: str, target_size=(768, 768)):
    """
    roads/000_condition.png + masks/000_mask.png ìŒì„ ë¡œë“œí•˜ê³ 
    SD ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
    """
    cond_path = ROADS_DIR / f"{id_str}_condition.png"
    mask_path = MASKS_DIR / f"{id_str}_mask.png"

    if not cond_path.exists():
        raise FileNotFoundError(cond_path)
    if not mask_path.exists():
        raise FileNotFoundError(mask_path)

    cond = Image.open(cond_path).convert("RGB")
    mask = Image.open(mask_path).convert("L")

    cond = cond.resize(target_size, Image.BILINEAR)
    mask = mask.resize(target_size, Image.NEAREST)

    return cond, mask


def apply_mask(image: Image.Image, mask: Image.Image) -> Image.Image:
    """
    ìƒì„±ëœ ì´ë¯¸ì§€ì—ì„œ mask ë°–(ê²€ì€ ì˜ì—­)ì„ í°ìƒ‰ìœ¼ë¡œ ì²˜ë¦¬
    """
    img_np = np.array(image)
    mask_np = np.array(mask)

    # mask: í°ìƒ‰(255) = keep, ê²€ì •(0) = outside
    outside = mask_np < 128
    img_np[outside] = 255  # ë°”ê¹¥ ì˜ì—­ í°ìƒ‰

    return Image.fromarray(img_np)


# =========================
# 4. ë©”ì¸ ìƒì„± í•¨ìˆ˜
# =========================

def generate_landuse_for_id(pipe, id_str: str, device="cuda"):
    cond_img, mask_img = load_pair_images(id_str)

    prompt = PROMPT_BASE
    negative_prompt = NEGATIVE_PROMPT

    print(f"ğŸ”¹ Generating land-use image for id={id_str} ...")

    # ì¬í˜„ ê°€ëŠ¥ì„±ì„ ìœ„í•´ seed ê³ ì • (ì›í•˜ë©´ None ìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
    generator = torch.Generator(device=device).manual_seed(1234)

    # Stable Diffusion + ControlNet ì‹¤í–‰
    out = pipe(
        prompt=prompt,
        image=cond_img,
        num_inference_steps=NUM_STEPS,
        guidance_scale=GUIDANCE,
        controlnet_conditioning_scale=CONTROL_SCALE,
        negative_prompt=negative_prompt,
        generator=generator,
    )

    gen_img = out.images[0]

    # mask ë°–ì€ í°ìƒ‰ìœ¼ë¡œ ì²˜ë¦¬
    gen_img_masked = apply_mask(gen_img, mask_img)

    # ì €ì¥
    out_path = OUT_DIR / f"{id_str}_landuse.png"
    gen_img_masked.save(out_path)
    print(f"âœ… Saved: {out_path}")


# =========================
# 5. ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# =========================

def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ‘‰ Using device: {device}")

    pipe = load_pipeline(device=device)

    # roads/ í´ë”ì— ìˆëŠ” *_condition.png íŒŒì¼ë“¤ ê¸°ì¤€ìœ¼ë¡œ id ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°
    ids = sorted([p.stem.replace("_condition", "") for p in ROADS_DIR.glob("*_condition.png")])

    print("ğŸ¯ Target IDs:", ids)

    for id_str in ids:
        generate_landuse_for_id(pipe, id_str, device=device)


if __name__ == "__main__":
    main()
